# Source: katib/examples/v1beta1/hp-tuning/hyperband.yaml
# This example is slightly modified from upstream to consume less resources.
# There's a `modified` comment where we diverge from upstream.
# When updating this file, make sure to keep those modifications.
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: hyperband
spec:
  parallelTrialCount: 2
  maxTrialCount: 2
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - Train-accuracy
  algorithm:
    algorithmName: hyperband
    algorithmSettings:
      - name: "resource_name"
        value: "num-epochs"
      - name: "eta"
        value: "2"
      - name: "r_l"
        value: "2"
  maxFailedTrialCount: 2
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: num-layers
      parameterType: int
      feasibleSpace:
        min: "2"
        max: "5"
    - name: optimizer
      parameterType: categorical
      feasibleSpace:
        list:
          - sgd
          - adam
          - ftrl
    - name: num-epochs
      parameterType: int
      feasibleSpace:
        min: "1"
        max: "1"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberLayers
        description: Number of training model layers
        reference: num-layers
      - name: optimizer
        description: Training model optimizer (sdg, adam or ftrl)
        reference: optimizer
      - name: numberEpochs
        description: Number of epochs to train the model
        reference: num-epochs
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: docker.io/kubeflowkatib/mxnet-mnist:v0.17.0
                command:
                  - "python3"
                  - "/opt/mxnet-mnist/mnist.py"
                  - "--batch-size=32"
                  - "--lr=${trialParameters.learningRate}"
                  - "--num-layers=${trialParameters.numberLayers}"
                  - "--optimizer=${trialParameters.optimizer}"
                  - "--num-epochs=${trialParameters.numberEpochs}"
                resources:  # modified
                  limits:  # modified
                    memory: "2Gi"  # modified
                    cpu: "1"  # modified
            restartPolicy: Never
