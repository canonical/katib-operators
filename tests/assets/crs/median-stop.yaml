# Source: katib/examples/v1beta1/hp-tuning/grid.yaml
# This example is slightly modified from upstream to consume less resources.
# There's a `modified` comment where we diverge from upstream.
# When updating this file, make sure to keep those modifications.
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: median-stop
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - Train-accuracy
  algorithm:
    algorithmName: random
  earlyStopping:
    algorithmName: medianstop
    algorithmSettings:
      - name: min_trials_required
        value: "1"
      - name: start_step
        value: "2"
  parallelTrialCount: 1  # modified
  maxTrialCount: 1  # modified
  maxFailedTrialCount: 1  # modified
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.5"
    - name: num-epochs
      parameterType: int
      feasibleSpace:
        min: "3"
        max: "4"
  trialTemplate:
    retain: true
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberEpochs
        description: Number of epochs to train the model
        reference: num-epochs
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: docker.io/kubeflowkatib/mxnet-mnist:v0.15.0
                command:
                  - "python3"
                  - "/opt/mxnet-mnist/mnist.py"
                  - "--batch-size=64"
                  - "--lr=${trialParameters.learningRate}"
                  - "--num-epochs=${trialParameters.numberEpochs}"
                resources:  # modified
                  limits:  # modified
                    memory: "2Gi"  # modified
                    cpu: "1"  # modified
            restartPolicy: Never
